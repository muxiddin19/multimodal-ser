<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ACL 2026 - Enhanced Multimodal Speech Emotion Recognition</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Fira+Code&display=swap" rel="stylesheet">
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }

        body {
            font-family: 'Inter', sans-serif;
            background: #0a0a1a;
            color: #fff;
            overflow: hidden;
        }

        .slide {
            display: none;
            width: 100vw;
            height: 100vh;
            padding: 60px 80px;
            background: linear-gradient(135deg, #0a0a1a 0%, #1a1a3e 100%);
            position: relative;
        }

        .slide.active { display: flex; flex-direction: column; }

        .slide-number {
            position: absolute;
            bottom: 30px;
            right: 40px;
            font-size: 14px;
            color: #666;
        }

        h1 {
            font-size: 2.8em;
            font-weight: 700;
            margin-bottom: 30px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }

        h2 {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 25px;
            color: #fff;
        }

        h3 {
            font-size: 1.4em;
            font-weight: 500;
            margin: 20px 0 15px;
            color: #a5b4fc;
        }

        p, li {
            font-size: 1.2em;
            line-height: 1.7;
            color: #d1d5db;
        }

        ul { margin-left: 30px; }
        li { margin: 12px 0; }

        .highlight {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            font-weight: 600;
        }

        .title-slide {
            justify-content: center;
            align-items: center;
            text-align: center;
        }

        .title-slide h1 {
            font-size: 3.2em;
            margin-bottom: 20px;
        }

        .title-slide .subtitle {
            font-size: 1.5em;
            color: #a5b4fc;
            margin-bottom: 40px;
        }

        .title-slide .meta {
            font-size: 1.1em;
            color: #6b7280;
        }

        .two-col {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 60px;
            flex: 1;
        }

        .card {
            background: rgba(255,255,255,0.05);
            border-radius: 16px;
            padding: 30px;
            border: 1px solid rgba(255,255,255,0.1);
        }

        .stat-card {
            text-align: center;
            padding: 25px;
        }

        .stat-value {
            font-size: 3em;
            font-weight: 700;
            background: linear-gradient(135deg, #10b981 0%, #3b82f6 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }

        .stat-label {
            font-size: 1em;
            color: #9ca3af;
            margin-top: 10px;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }

        th, td {
            padding: 15px 20px;
            text-align: left;
            border-bottom: 1px solid rgba(255,255,255,0.1);
        }

        th {
            background: rgba(102, 126, 234, 0.2);
            font-weight: 600;
            color: #a5b4fc;
        }

        .good { color: #10b981; }
        .warning { color: #f59e0b; }
        .bad { color: #ef4444; }

        .tag {
            display: inline-block;
            padding: 4px 12px;
            border-radius: 20px;
            font-size: 0.85em;
            font-weight: 500;
        }

        .tag-green { background: rgba(16,185,129,0.2); color: #10b981; }
        .tag-blue { background: rgba(59,130,246,0.2); color: #3b82f6; }
        .tag-yellow { background: rgba(245,158,11,0.2); color: #f59e0b; }
        .tag-red { background: rgba(239,68,68,0.2); color: #ef4444; }

        .architecture {
            background: rgba(0,0,0,0.3);
            border-radius: 12px;
            padding: 30px;
            font-family: 'Fira Code', monospace;
            font-size: 0.9em;
            line-height: 1.8;
            white-space: pre;
            overflow-x: auto;
        }

        .nav {
            position: fixed;
            bottom: 30px;
            left: 50%;
            transform: translateX(-50%);
            display: flex;
            gap: 15px;
            z-index: 100;
        }

        .nav button {
            padding: 12px 25px;
            border: none;
            border-radius: 8px;
            background: rgba(102, 126, 234, 0.3);
            color: #fff;
            cursor: pointer;
            font-size: 1em;
            transition: all 0.3s;
        }

        .nav button:hover {
            background: rgba(102, 126, 234, 0.6);
        }

        .progress {
            position: fixed;
            top: 0;
            left: 0;
            height: 4px;
            background: linear-gradient(90deg, #667eea, #764ba2);
            transition: width 0.3s;
        }

        .emoji { font-size: 1.5em; margin-right: 10px; }

        .flex-center {
            display: flex;
            justify-content: center;
            align-items: center;
            gap: 30px;
            flex-wrap: wrap;
        }

        .contribution-box {
            background: linear-gradient(135deg, rgba(102,126,234,0.2) 0%, rgba(118,75,162,0.2) 100%);
            border: 1px solid rgba(102,126,234,0.3);
            border-radius: 16px;
            padding: 25px;
            flex: 1;
            min-width: 280px;
        }

        .contribution-box h4 {
            font-size: 1.2em;
            color: #a5b4fc;
            margin-bottom: 15px;
        }

        .verdict {
            background: linear-gradient(135deg, rgba(16,185,129,0.2) 0%, rgba(59,130,246,0.2) 100%);
            border: 2px solid rgba(16,185,129,0.4);
            border-radius: 16px;
            padding: 30px;
            text-align: center;
            margin-top: 30px;
        }

        .verdict h3 {
            color: #10b981;
            font-size: 1.6em;
        }

        .checklist { list-style: none; margin-left: 0; }
        .checklist li { padding-left: 35px; position: relative; }
        .checklist li::before {
            content: 'â˜';
            position: absolute;
            left: 0;
            color: #f59e0b;
        }
        .checklist li.done::before {
            content: 'âœ“';
            color: #10b981;
        }
    </style>
</head>
<body>
    <div class="progress" id="progress"></div>

    <!-- Slide 1: Title -->
    <div class="slide title-slide active">
        <h1>Enhanced Multimodal Speech Emotion Recognition</h1>
        <p class="subtitle">VAD-Guided Cross-Attention with Interpretable Fusion</p>
        <p class="meta">
            ACL 2026 Main Conference Proposal<br><br>
            Advisor Meeting | December 2024
        </p>
        <div class="slide-number">1 / 14</div>
    </div>

    <!-- Slide 2: Problem -->
    <div class="slide">
        <h1>The Problem</h1>
        <div class="two-col">
            <div>
                <h3><span class="emoji">âš ï¸</span>Current Limitations</h3>
                <ul>
                    <li><strong>Fixed fusion weights</strong> - Static modality weighting ignores sample-specific importance</li>
                    <li><strong>Black-box attention</strong> - Cross-attention lacks interpretability</li>
                    <li><strong>Class imbalance</strong> - Minority emotions (happiness, frustration) underperform</li>
                    <li><strong>Single-dataset bias</strong> - Most work only evaluates on IEMOCAP</li>
                </ul>
            </div>
            <div>
                <h3><span class="emoji">ğŸ¯</span>Our Goal</h3>
                <div class="card" style="margin-top: 20px;">
                    <p>Design an <span class="highlight">interpretable</span>, <span class="highlight">psychology-informed</span> multimodal fusion architecture that achieves <span class="highlight">SOTA performance</span> across multiple datasets</p>
                </div>
                <h3 style="margin-top: 40px;"><span class="emoji">ğŸ“Š</span>Target Datasets</h3>
                <ul>
                    <li>IEMOCAP (5/6-class)</li>
                    <li>CREMA-D (4-class)</li>
                    <li>MELD (4-class)</li>
                </ul>
            </div>
        </div>
        <div class="slide-number">2 / 14</div>
    </div>

    <!-- Slide 3: Contributions -->
    <div class="slide">
        <h1>Novel Contributions</h1>
        <div class="flex-center" style="margin-top: 30px;">
            <div class="contribution-box">
                <h4><span class="emoji">ğŸ§ </span>VAD-Guided Attention</h4>
                <p>First to use <strong>Valence-Arousal-Dominance</strong> psychological space to guide cross-modal attention</p>
                <p style="margin-top: 15px; font-family: 'Fira Code', monospace; font-size: 0.9em; color: #a5b4fc;">
                    A = softmax(QK<sup>T</sup>/âˆšd + Î»Â·M<sub>VAD</sub>)
                </p>
            </div>
            <div class="contribution-box">
                <h4><span class="emoji">âš–ï¸</span>Constrained Fusion</h4>
                <p>Gates <strong>sum to 1</strong> for interpretability - reveals exact modality contribution per sample</p>
                <p style="margin-top: 15px; font-family: 'Fira Code', monospace; font-size: 0.9em; color: #a5b4fc;">
                    Î±<sub>t</sub> + Î±<sub>a</sub> + Î±<sub>i</sub> = 1.0
                </p>
            </div>
            <div class="contribution-box">
                <h4><span class="emoji">ğŸ¯</span>Hard Negative MICL</h4>
                <p>Focus on <strong>difficult cross-modal pairs</strong> with curriculum-based hardness increase</p>
                <p style="margin-top: 15px; font-family: 'Fira Code', monospace; font-size: 0.9em; color: #a5b4fc;">
                    L = InfoNCE + 0.5Â·MarginLoss
                </p>
            </div>
        </div>
        <div class="slide-number">3 / 14</div>
    </div>

    <!-- Slide 4: Architecture -->
    <div class="slide">
        <h1>Architecture Overview</h1>
        <div class="architecture">
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         INPUT FEATURES                               â”‚
â”‚           BERT (768d)                    emotion2vec (1024d)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                                â”‚
                â–¼                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PROJECTION TO COMMON SPACE (384d)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                                â”‚
                â–¼                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 SELF-ATTENTION ENCODERS (8 heads)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                                â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           <span style="color:#10b981">â˜… VAD-GUIDED CROSS-ATTENTION (Novel) â˜…</span>                       â”‚
â”‚           Projects to VAD space, computes affinity, Î»=0.5            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           <span style="color:#10b981">â˜… CONSTRAINED ADAPTIVE FUSION (Novel) â˜…</span>                     â”‚
â”‚           Î±_text + Î±_audio + Î±_interaction = 1.0                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â–¼                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   EMOTION CLASSIFIER     â”‚     â”‚   <span style="color:#10b981">â˜… MICL + HARD NEGATIVES â˜…</span>       â”‚
â”‚   (Focal Loss Î³=2.0)     â”‚     â”‚   Cross-modal contrastive          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                        <span style="color:#a5b4fc">Parameters: 13.3M</span>
        </div>
        <div class="slide-number">4 / 14</div>
    </div>

    <!-- Slide 5: Results -->
    <div class="slide">
        <h1>Experimental Results</h1>
        <table>
            <tr>
                <th>Dataset</th>
                <th>Classes</th>
                <th>Val UA</th>
                <th>Test UA</th>
                <th>vs Previous</th>
            </tr>
            <tr>
                <td>IEMOCAP</td>
                <td>5</td>
                <td>77.41 Â± 0.37%</td>
                <td>75.61 Â± 0.42%</td>
                <td><span class="tag tag-blue">Comparable</span></td>
            </tr>
            <tr>
                <td>IEMOCAP</td>
                <td>6</td>
                <td>68.75 Â± 0.58%</td>
                <td>65.69 Â± 0.56%</td>
                <td><span class="tag tag-green">+3.75%</span></td>
            </tr>
            <tr style="background: rgba(16,185,129,0.1);">
                <td><strong>CREMA-D</strong></td>
                <td>4</td>
                <td><strong class="good">92.90 Â± 0.34%</strong></td>
                <td><strong class="good">92.70 Â± 0.35%</strong></td>
                <td><span class="tag tag-green">SOTA!</span></td>
            </tr>
            <tr>
                <td>MELD</td>
                <td>4</td>
                <td>63.66 Â± 0.72%</td>
                <td>58.93 Â± 0.45%</td>
                <td><span class="tag tag-yellow">Challenging</span></td>
            </tr>
        </table>
        <div class="flex-center" style="margin-top: 30px;">
            <div class="stat-card card">
                <div class="stat-value">92.9%</div>
                <div class="stat-label">CREMA-D SOTA</div>
            </div>
            <div class="stat-card card">
                <div class="stat-value">+3.75%</div>
                <div class="stat-label">IEMOCAP 6-class</div>
            </div>
            <div class="stat-card card">
                <div class="stat-value">3</div>
                <div class="stat-label">Datasets Evaluated</div>
            </div>
        </div>
        <div class="slide-number">5 / 14</div>
    </div>

    <!-- Slide 6: Fusion Analysis -->
    <div class="slide">
        <h1>Interpretable Fusion Analysis</h1>
        <p style="margin-bottom: 30px;">Our constrained fusion reveals <span class="highlight">modality importance per dataset</span></p>
        <table>
            <tr>
                <th>Dataset</th>
                <th>Text Gate</th>
                <th>Audio Gate</th>
                <th>Interaction</th>
                <th>Insight</th>
            </tr>
            <tr>
                <td>IEMOCAP 5-class</td>
                <td><strong class="highlight">54.3%</strong></td>
                <td>45.5%</td>
                <td>0.2%</td>
                <td>Balanced - text helps conversation</td>
            </tr>
            <tr>
                <td>IEMOCAP 6-class</td>
                <td>41.4%</td>
                <td><strong class="highlight">58.4%</strong></td>
                <td>0.2%</td>
                <td>Audio dominates fine-grained</td>
            </tr>
            <tr>
                <td>CREMA-D</td>
                <td>23.1%</td>
                <td><strong class="highlight">76.6%</strong></td>
                <td>0.3%</td>
                <td>Acted emotions are vocal</td>
            </tr>
        </table>
        <div class="card" style="margin-top: 40px;">
            <h3><span class="emoji">ğŸ’¡</span>Key Insight</h3>
            <p>The model <strong>automatically learns</strong> optimal modality weighting per domain. CREMA-D (acted) relies on audio, while conversational IEMOCAP uses balanced fusion.</p>
        </div>
        <div class="slide-number">6 / 14</div>
    </div>

    <!-- Slide 7: What's Missing -->
    <div class="slide">
        <h1>Honest Assessment: What's Missing</h1>
        <div class="two-col">
            <div>
                <h3><span class="emoji">ğŸ”´</span>Must Have Before Submission</h3>
                <ul class="checklist">
                    <li>Stronger baselines (emotion2vec+text, TelME, CARAT)</li>
                    <li>Statistical significance tests (paired t-test)</li>
                    <li>Complete ablation study (remove each component)</li>
                    <li>Error analysis (confusion matrices, failure cases)</li>
                </ul>
            </div>
            <div>
                <h3><span class="emoji">ğŸŸ¡</span>Should Have</h3>
                <ul class="checklist">
                    <li>Cross-dataset transfer (IEMOCAP â†’ CREMA-D)</li>
                    <li>Few-shot learning (10%, 20% labeled)</li>
                    <li>Cross-lingual evaluation (non-English)</li>
                </ul>
                <h3 style="margin-top: 30px;"><span class="emoji">ğŸŸ¢</span>Nice to Have</h3>
                <ul class="checklist">
                    <li>Human evaluation on Sentimentogram</li>
                    <li>Efficiency analysis (inference time)</li>
                </ul>
            </div>
        </div>
        <div class="slide-number">7 / 14</div>
    </div>

    <!-- Slide 8: Why ACL -->
    <div class="slide">
        <h1>Why ACL 2026?</h1>
        <div class="two-col">
            <div>
                <h3><span class="emoji">âœ…</span>Fits ACL Scope</h3>
                <ul>
                    <li><strong>Multimodal NLP</strong> - Text + speech fusion</li>
                    <li><strong>Interpretability</strong> - Explainable fusion weights</li>
                    <li><strong>Psychological grounding</strong> - VAD theory</li>
                    <li><strong>Practical application</strong> - Sentimentogram demo</li>
                </ul>
            </div>
            <div>
                <h3><span class="emoji">â­</span>Novelty Assessment</h3>
                <table>
                    <tr>
                        <th>Contribution</th>
                        <th>Level</th>
                    </tr>
                    <tr>
                        <td>VAD-guided attention</td>
                        <td><span class="tag tag-green">High</span></td>
                    </tr>
                    <tr>
                        <td>Constrained fusion</td>
                        <td><span class="tag tag-green">Medium-High</span></td>
                    </tr>
                    <tr>
                        <td>Hard negative MICL</td>
                        <td><span class="tag tag-blue">Medium</span></td>
                    </tr>
                    <tr>
                        <td>Multi-dataset eval</td>
                        <td><span class="tag tag-blue">Medium</span></td>
                    </tr>
                </table>
            </div>
        </div>
        <div class="slide-number">8 / 14</div>
    </div>

    <!-- Slide 9: Timeline -->
    <div class="slide">
        <h1>Timeline to ACL 2026</h1>
        <p style="margin-bottom: 30px;">Estimated submission deadline: <strong>February 2026</strong></p>
        <table>
            <tr>
                <th>Phase</th>
                <th>Duration</th>
                <th>Tasks</th>
            </tr>
            <tr>
                <td><span class="tag tag-blue">Phase 1</span></td>
                <td>2-3 weeks</td>
                <td>Implement and run SOTA baseline comparisons</td>
            </tr>
            <tr>
                <td><span class="tag tag-blue">Phase 2</span></td>
                <td>1-2 weeks</td>
                <td>Systematic ablation study</td>
            </tr>
            <tr>
                <td><span class="tag tag-blue">Phase 3</span></td>
                <td>1-2 weeks</td>
                <td>Error analysis, cross-dataset transfer</td>
            </tr>
            <tr>
                <td><span class="tag tag-green">Phase 4</span></td>
                <td>3-4 weeks</td>
                <td>Writing: draft, figures, tables</td>
            </tr>
            <tr>
                <td><span class="tag tag-green">Phase 5</span></td>
                <td>2 weeks</td>
                <td>Advisor feedback and polish</td>
            </tr>
        </table>
        <div class="card" style="margin-top: 30px; text-align: center;">
            <p><strong>Total: ~10-13 weeks</strong></p>
        </div>
        <div class="slide-number">9 / 14</div>
    </div>

    <!-- Slide 10: Demo -->
    <div class="slide">
        <h1>Demo: Sentimentogram</h1>
        <p style="margin-bottom: 30px;">Practical application: <span class="highlight">Emotion-aware subtitles</span></p>
        <div class="two-col">
            <div>
                <h3><span class="emoji">ğŸ¬</span>Features</h3>
                <ul>
                    <li>Real-time emotion detection from video</li>
                    <li>Word-level emotion styling</li>
                    <li>Emotion-specific typography</li>
                    <li>Cultural adaptation (Western/Eastern)</li>
                </ul>
                <h3 style="margin-top: 30px;"><span class="emoji">ğŸ”§</span>Pipeline</h3>
                <div class="card">
                    <p style="font-family: 'Fira Code', monospace; font-size: 0.9em;">
                        Video â†’ Whisper STT â†’ BERT + emotion2vec â†’ Enhanced Model â†’ HTML
                    </p>
                </div>
            </div>
            <div>
                <h3><span class="emoji">ğŸ¨</span>Typography by Emotion</h3>
                <div style="padding: 20px;">
                    <p style="font-family: 'Fredoka One', cursive; color: #FFD700; font-size: 1.3em;">Happy - Bouncy Gold</p>
                    <p style="font-family: serif; font-style: italic; color: #6B9BD2; font-size: 1.1em;">Sadness - Elegant Blue</p>
                    <p style="color: #C0C0C0;">Neutral - Clean Gray</p>
                    <p style="font-family: 'Impact', sans-serif; color: #FF3333; font-size: 1.4em; text-transform: uppercase;">ANGER - BOLD RED</p>
                    <p style="font-family: 'Arial Narrow', sans-serif; color: #FF8C00;">Frustration - Tense Orange</p>
                </div>
            </div>
        </div>
        <div class="slide-number">10 / 14</div>
    </div>

    <!-- Slide 11: Questions for Advisor -->
    <div class="slide">
        <h1>Questions for Discussion</h1>
        <div style="margin-top: 30px;">
            <div class="card" style="margin-bottom: 20px;">
                <h3><span class="emoji">1ï¸âƒ£</span>Scope & Novelty</h3>
                <p>Is VAD-guided attention + interpretable fusion sufficient novelty for ACL main conference?</p>
            </div>
            <div class="card" style="margin-bottom: 20px;">
                <h3><span class="emoji">2ï¸âƒ£</span>Baselines Priority</h3>
                <p>Which baselines are most critical? emotion2vec+text, TelME, UniSER, or CARAT?</p>
            </div>
            <div class="card" style="margin-bottom: 20px;">
                <h3><span class="emoji">3ï¸âƒ£</span>Cross-lingual</h3>
                <p>Should we prioritize cross-lingual evaluation or focus on English datasets?</p>
            </div>
            <div class="card" style="margin-bottom: 20px;">
                <h3><span class="emoji">4ï¸âƒ£</span>Positioning</h3>
                <p>Main conference vs. Findings? Long paper (8 pages) vs. short paper (4 pages)?</p>
            </div>
        </div>
        <div class="slide-number">11 / 14</div>
    </div>

    <!-- Slide 12: Summary -->
    <div class="slide">
        <h1>Summary</h1>
        <div class="two-col">
            <div>
                <h3><span class="emoji">âœ…</span>What We Have</h3>
                <ul>
                    <li class="good">Novel VAD-guided cross-attention</li>
                    <li class="good">Interpretable constrained fusion</li>
                    <li class="good">SOTA on CREMA-D (92.90% UA)</li>
                    <li class="good">Multi-dataset evaluation</li>
                    <li class="good">Working demo (Sentimentogram)</li>
                </ul>
            </div>
            <div>
                <h3><span class="emoji">âš ï¸</span>What We Need</h3>
                <ul>
                    <li class="warning">Stronger baseline comparisons</li>
                    <li class="warning">Statistical significance tests</li>
                    <li class="warning">Complete ablation study</li>
                    <li class="warning">Error analysis</li>
                </ul>
            </div>
        </div>
        <div class="verdict">
            <h3><span class="emoji">ğŸ¯</span>Recommendation</h3>
            <p style="margin-top: 15px; font-size: 1.2em;">
                <strong>Proceed with ACL 2026 submission</strong> after completing baseline comparisons and ablation study.
                The work has sufficient novelty and strong results on CREMA-D.
            </p>
        </div>
        <div class="slide-number">12 / 14</div>
    </div>

    <!-- Slide 13: Thank You -->
    <div class="slide title-slide">
        <h1>Thank You</h1>
        <p class="subtitle">Questions & Discussion</p>
        <p class="meta" style="margin-top: 40px;">
            Code: github.com/[repo]<br>
            Demo: demo/output/result_enhanced.html
        </p>
        <div class="slide-number">13 / 14</div>
    </div>

    <!-- Slide 14: Backup - Per Class -->
    <div class="slide">
        <h1>Backup: Per-Class Performance</h1>
        <h3>IEMOCAP 6-class Breakdown</h3>
        <table>
            <tr>
                <th>Emotion</th>
                <th>F1-Score</th>
                <th>Support</th>
                <th>Analysis</th>
            </tr>
            <tr>
                <td>happiness</td>
                <td class="warning">44.6%</td>
                <td>65</td>
                <td><span class="tag tag-red">Very small sample</span></td>
            </tr>
            <tr>
                <td>sadness</td>
                <td class="good">75.9%</td>
                <td>143</td>
                <td><span class="tag tag-green">Good</span></td>
            </tr>
            <tr>
                <td>neutral</td>
                <td>64.2%</td>
                <td>258</td>
                <td><span class="tag tag-blue">Moderate</span></td>
            </tr>
            <tr>
                <td>anger</td>
                <td class="good">78.9%</td>
                <td>327</td>
                <td><span class="tag tag-green">Best</span></td>
            </tr>
            <tr>
                <td>excitement</td>
                <td class="good">73.3%</td>
                <td>238</td>
                <td><span class="tag tag-green">Good</span></td>
            </tr>
            <tr>
                <td>frustration</td>
                <td class="warning">48.7%</td>
                <td>481</td>
                <td><span class="tag tag-yellow">Confused with anger</span></td>
            </tr>
        </table>
        <div class="slide-number">14 / 14</div>
    </div>

    <div class="nav">
        <button onclick="prevSlide()">â† Previous</button>
        <button onclick="nextSlide()">Next â†’</button>
    </div>

    <script>
        let currentSlide = 0;
        const slides = document.querySelectorAll('.slide');
        const totalSlides = slides.length;
        const progress = document.getElementById('progress');

        function showSlide(n) {
            slides[currentSlide].classList.remove('active');
            currentSlide = (n + totalSlides) % totalSlides;
            slides[currentSlide].classList.add('active');
            progress.style.width = ((currentSlide + 1) / totalSlides * 100) + '%';
        }

        function nextSlide() { showSlide(currentSlide + 1); }
        function prevSlide() { showSlide(currentSlide - 1); }

        document.addEventListener('keydown', (e) => {
            if (e.key === 'ArrowRight' || e.key === ' ') nextSlide();
            if (e.key === 'ArrowLeft') prevSlide();
        });

        // Initial progress
        progress.style.width = (1 / totalSlides * 100) + '%';
    </script>
</body>
</html>
